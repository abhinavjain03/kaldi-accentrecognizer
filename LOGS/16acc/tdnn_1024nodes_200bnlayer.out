steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3/tdnn_1024nodes_200bnlayer/configs/network.xconfig --config-dir exp/nnet3/tdnn_1024nodes_200bnlayer/configs/
nnet3-init exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.config exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw
nnet3-info exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw 
nnet3-init exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.config exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw
nnet3-info exp/nnet3/tdnn_1024nodes_200bnlayer/configs//ref.raw 
./my_run.sh: calling get_egs.sh for generating examples with alignments as output
steps/nnet3/get_egs_mod.sh --cmvn-opts --norm-means=false --norm-vars=false --left-context 16 --right-context 12 --num-utts-subset 300 --nj 20 --num-pdfs 16 --samples-per-iter 400000 --cmd run.pl --frames-per-eg 8 data/cv_train_all_with_accents_hires exp/tri4_train_with_accents_ali exp/nnet3/tdnn_1024nodes_200bnlayer/egs
steps/nnet3/get_egs_mod.sh: feature type is raw
steps/nnet3/get_egs_mod.sh: working out number of frames of training data
steps/nnet3/get_egs_mod.sh: working out feature dim
steps/nnet3/get_egs_mod.sh: creating 9 archives, each with 366002 egs, with
steps/nnet3/get_egs_mod.sh:   8 labels per example, and (left,right) context = (16,12)
steps/nnet3/get_egs_mod.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3/tdnn_1024nodes_200bnlayer/egs/ali.ark,exp/nnet3/tdnn_1024nodes_200bnlayer/egs/ali.scp 
LOG (copy-int-vector[5.2.204~1-08848]:main():copy-int-vector.cc:83) Copied 64154 vectors of int32.
steps/nnet3/get_egs_mod.sh: Getting validation and training subset examples.
steps/nnet3/get_egs_mod.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/get_egs_mod.sh: Generating training examples on disk
steps/nnet3/get_egs_mod.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs_mod.sh: removing temporary archives
steps/nnet3/get_egs_mod.sh: removing temporary alignments and transforms
steps/nnet3/get_egs_mod.sh: Finished preparing training examples
2018-02-15 19:21:04,015 [steps/nnet3/train_raw_dnn.py:34 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2018-02-15 19:21:04,027 [steps/nnet3/train_raw_dnn.py:172 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_average_posteriors': False,
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3/tdnn_1024nodes_200bnlayer',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': 'exp/nnet3/tdnn_1024nodes_200bnlayer/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/cv_train_all_with_accents_hires',
 'final_effective_lrate': 0.00017,
 'frames_per_eg': 8,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.0017,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '512',
 'momentum': 0.0,
 'nj': 4,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 9,
 'num_jobs_initial': 3,
 'online_ivector_dir': None,
 'preserve_model_interval': 20,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': True,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'targets_scp': None,
 'transform_dir': None,
 'use_dense_targets': False,
 'use_gpu': True}
2018-02-15 19:21:04,045 [steps/libs/nnet3/train/common.py:440 - verify_egs_dir - WARNING ] The ivector ids are not used. It's your responsibility to make sure the ivector extractor has been used consistently
2018-02-15 19:21:04,046 [steps/nnet3/train_raw_dnn.py:283 - train - INFO ] Preparing the initial network.
2018-02-15 19:21:05,102 [steps/nnet3/train_raw_dnn.py:322 - train - INFO ] Training will run for 2.0 epochs = 24 iterations
2018-02-15 19:21:05,102 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-02-15 19:21:05,107 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.0051.
2018-02-15 19:23:33,807 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 1)
2018-02-15 19:23:33,822 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 1, learning rate is 0.0048611256045.
2018-02-15 19:25:39,188 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 2)
2018-02-15 19:25:39,199 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 2, learning rate is 0.00617791951443.
2018-02-15 19:28:27,392 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 3)
2018-02-15 19:28:27,401 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 3, learning rate is 0.00579514715327.
2018-02-15 19:31:11,445 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 4)
2018-02-15 19:31:11,455 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 4, learning rate is 0.0054360906531.
2018-02-15 19:33:59,482 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 5)
2018-02-15 19:33:59,497 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 5, learning rate is 0.00509928062346.
2018-02-15 19:36:45,926 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 6)
2018-02-15 19:36:45,939 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 6, learning rate is 0.00597917339319.
2018-02-15 19:40:13,068 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 7)
2018-02-15 19:40:13,081 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 7, learning rate is 0.0055197438684.
2018-02-15 19:43:39,545 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 8)
2018-02-15 19:43:39,555 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 8, learning rate is 0.00509561612771.
2018-02-15 19:47:05,139 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 9)
2018-02-15 19:47:05,150 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 9, learning rate is 0.00470407764202.
2018-02-15 19:50:33,415 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 10)
2018-02-15 19:50:33,425 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 10, learning rate is 0.00521114917.
2018-02-15 19:54:42,278 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 11)
2018-02-15 19:54:42,298 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 11, learning rate is 0.00473442061029.
2018-02-15 19:58:47,799 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 12)
2018-02-15 19:58:47,807 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 12, learning rate is 0.00430130433497.
2018-02-15 20:02:49,701 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 13)
2018-02-15 20:02:49,707 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 13, learning rate is 0.00390781058655.
2018-02-15 20:06:58,259 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 14)
2018-02-15 20:06:58,265 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 14, learning rate is 0.00414203370023.
2018-02-15 20:10:03,834 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 15)
2018-02-15 20:10:03,841 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 15, learning rate is 0.00370341615701.
2018-02-15 20:13:18,683 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 16)
2018-02-15 20:13:18,689 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 16, learning rate is 0.00331124568863.
2018-02-15 20:16:43,285 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 17)
2018-02-15 20:16:43,292 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 17, learning rate is 0.00296060381701.
2018-02-15 20:19:55,450 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 18)
2018-02-15 20:19:55,455 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 18, learning rate is 0.00302524903161.
2018-02-15 20:23:42,490 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 19)
2018-02-15 20:23:42,496 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 19, learning rate is 0.00266198482282.
2018-02-15 20:27:11,495 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 20)
2018-02-15 20:27:11,501 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 20, learning rate is 0.00234234045624.
2018-02-15 20:33:34,862 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 21)
2018-02-15 20:33:34,868 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 21, learning rate is 0.00206107817216.
2018-02-15 20:37:19,885 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 22)
2018-02-15 20:37:19,891 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 22, learning rate is 0.00204028779121.
2018-02-15 20:41:12,730 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 23)
2018-02-15 20:41:12,736 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 23, learning rate is 0.00153.
2018-02-15 20:45:07,910 [steps/nnet3/train_raw_dnn.py:395 - train - INFO ] Doing final combination to produce final.raw
2018-02-15 20:45:07,911 [steps/libs/nnet3/train/frame_level_objf/common.py:466 - combine_models - INFO ] Combining set([13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]) models.
2018-02-15 20:53:15,840 [steps/nnet3/train_raw_dnn.py:417 - train - INFO ] Cleaning up the experiment directory exp/nnet3/tdnn_1024nodes_200bnlayer
exp/nnet3/tdnn_1024nodes_200bnlayer: num-iters=24 nj=3..9 num-params=10.1M dim=40->16 combine=-0.51->-0.28 loglike:train/valid[15,23]=(-0.68,-0.74/-1.06,-1.38) accuracy:train/valid[15,23]=(0.823,0.843/0.755,0.784)
steps/nnet3/train_raw_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial 3 --trainer.optimization.num-jobs-final 9 --trainer.optimization.initial-effective-lrate 0.0017 --trainer.optimization.final-effective-lrate 0.00017 --egs.dir exp/nnet3/tdnn_1024nodes_200bnlayer/egs --cleanup.preserve-model-interval 20 --use-gpu true --use-dense-targets false --feat-dir=data/cv_train_all_with_accents_hires --reporting.email= --dir exp/nnet3/tdnn_1024nodes_200bnlayer
['steps/nnet3/train_raw_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial', '3', '--trainer.optimization.num-jobs-final', '9', '--trainer.optimization.initial-effective-lrate', '0.0017', '--trainer.optimization.final-effective-lrate', '0.00017', '--egs.dir', 'exp/nnet3/tdnn_1024nodes_200bnlayer/egs', '--cleanup.preserve-model-interval', '20', '--use-gpu', 'true', '--use-dense-targets', 'false', '--feat-dir=data/cv_train_all_with_accents_hires', '--reporting.email=', '--dir', 'exp/nnet3/tdnn_1024nodes_200bnlayer']
